---
jupyter: python3
---

<link rel="stylesheet" type="text/css" href="..\style.css">
<header>
<dev class="home"><b><u>HOME</u></b></dev>
<a class="order" href="https://coconala.com/users/3496338"><b><u>ご依頼とご相談</u></b></a>
<a href="https://twitter.com/essay_Positive">
<img class="face_logo" src="..\pictures\logo-white.png" alt="fece_logo">
</a>
</header>

<h1>統計の基本概念を理解しよう</h1>  
&nbsp;統計学は私たちが日常的に取り扱うデータを解釈し、意味を理解するための重要なツールです。統計の世界に足を踏み入れる際に理解しておくべき基本概念について、簡単に紹介します。  

<h2>平均 (Mean)</h2>  
データセットの平均は、そのデータセットの合計値をデータ数で割ることで求められます。例えば、10個のデータがある場合、それらの値を全て合計して10で割ります。平均はデータの中心傾向を表す指標であり、データ全体の代表値として広く用いられます。  

<h2>分散 (Variance)</h2>  
分散は、データが平均からどれだけばらついているかを示す指標です。データポイントが平均値からどれだけ離れているかを示すため、分散が大きいほどデータは散らばっています。分散を求めるには、各データポイントと平均値の差の二乗を合計した後、データ数で割ります。  

<h2>正規分布 (Normal Distribution)</h2>  
正規分布は、統計学で最も一般的に見られる分布です。ベルカーブとしても知られており、その形状は中央が高く左右対称であり、平均値周辺のデータが最も頻繁に発生し、それぞれの標準偏差の範囲内にデータが集中しています。多くの自然現象や人間の行動パターンは正規分布に従います。  

<h2>中心極限定理 (Central Limit Theorem)</h2>  
中心極限定理は、大数の法則の一種であり、サンプルサイズが大きくなるにつれて、標本平均が正規分布に近づくことを述べています。この定理により、標本の分布に関係なく、標本平均の分布は正規分布になります。中心極限定理は、統計学の多くの分野で使用され、標本の大きさや分布がどのようであっても適用される強力なツールです。  

これらの基本概念を理解することは、統計学の学習の基盤となります。データを分析し、現象を理解する際に、これらの概念を活用してください。

<link rel="stylesheet" type="text/css" href="..\style.css">
<h1>中心極限定理の数値解析の例</h1>  
統計学において、中心極限定理は非常に重要な概念です。この定理は、標本の分布がどのような形であっても、そのサンプルの数が大きくなればなるほど、サンプルの平均値が正規分布に近づくことを示しています。  
ここでは、サイコロの出目の例を通じて、中心極限定理を理解してみましょう。  

<h2>1.サイコロの出目の生成</h2>  
まずは、1から6が同じ確率で出るサイコロの出目を生成します。このような、確率の分布が一定の場合の分布を一様分布といいます。1から6までの一様分布からサンプルを1000個作成すると以下のようになります。

```{python}
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib

# サンプル数
n_trials = 1000

# 一様分布からのサンプリング
samples = np.random.randint(1, 7, n_trials)

# ヒストグラムで分布を可視化
plt.figure(figsize=(6, 3))
plt.hist(samples, bins=np.arange(0.5, 7.5), density=True, alpha=0.7)
plt.title(f'1から6までの一様分布で{n_trials}回試行した結果')
plt.xlabel('確率変数X')
plt.ylabel('頻度の割合')
plt.grid(True)
plt.show()
```

<link rel="stylesheet" type="text/css" href="..\style.css">
<h2>2.中心極限定理の検証</h2>

次に、中心極限定理を検証します。中心極限定理によれば、n個のサンプルの平均は、nが大きくなるにつれて正規分布に近づくはずです。ここでは、一様分布のサンプルを3回作成しその平均$\bar{X}_i$を求める試行を1セットとし、1000セット分の試行をした場合の平均の分布を確認します。1セット当たりの回数が多くなるほど、$\bar{X}_i$($i$=1,2,…,1000)の分布は正規分布に近づくはずです。

```{python}
def plot_histogram(n_values, n_trials):
    # 平均の計算
    means = np.mean(np.random.randint(1, 7, (n_trials, n_values)), axis=1)

    # ヒストグラムで分布を可視化
    plt.figure(figsize=(6, 3))
    plt.hist(means, bins=np.arange(1,6,1/n_values), density=True, alpha=0.7)
    plt.title(f'{n_values}回サイコロを投げて平均を算出する試行を{n_trials}回繰り返した結果')
    plt.xlabel(r'各試行での確率変数の平均値$\bar{X}$')
    plt.ylabel('頻度の割合')
    plt.grid(True)
    plt.show()
```

```{python}
plot_histogram(n_values=2, n_trials=1000)
```

```{python}
plot_histogram(n_values=5, n_trials=1000)
```

```{python}
plot_histogram(n_values=10, n_trials=1000)
```

```{python}
plot_histogram(n_values=30, n_trials=1000)
```

n_values(一度の試行で投げるサイコロの数)が増えるにつれて、分布の形が正規分布に近づくことがわかりますね。  
他にも、n_valuesが増えるにつれ分布の形がどんどん中央の3.5の周りに集中していますね。これは$n$回サイコロを投げた時の平均$\bar{X}$の分散が、$n$に反比例するためです。そのため、$n$を増やせば増やすほど、ばらつきは小さくなります。

<link rel="stylesheet" type="text/css" href="..\style.css">
<h1>終わりに</h1>

この記事では、中心極限定理とその重要性について説明しました。中心極限定理は、統計学と確率論の基本的な概念であり、大量のデータを扱う際に特に重要です。この定理により、大量のランダムな確率変数の合計（または平均）が正規分布に近づくことがわかりました。また、確率変数のサンプル数が大きくなるにつれ、そのばらつきが小さくなることも確認しました。

中心極限定理の理解は、データ分析や機械学習の分野での仮説検定や信頼区間の計算など、多くの実用的な応用に役立ちます。また、この定理は、大数の法則と並んで、確率論の基本的な結果の一つとも言えます。

今後も統計学やデータ分析に関するさまざまなトピックを取り上げていきますので、ぜひご期待ください。ありがとうございました。


